wandb:
  wandb_log: True
  name: ''
  project: 'SCDISENTANGLE_REPRODUCE'
  group: ''

UI:
  launch: False
  ide: True

hardware:
  device: 0

other:
  experiment_name: True
  verbose: True

data: 
  file_path: '/data/Experiments/Benchmark/SCDISENTANGLE_REPRODUCE/Datasets/preprocessed_datasets/norman.h5ad'
  default_normalization: False
  use_counts: True
  label_keys: ['condition', 'perturbation1', 'perturbation2', 'sc_cell_ids']
    
  highly_variable: False 
  min_gene_counts: False
  min_cell_counts: False
  train_size: 1
  val_size: 0
  test_size: 0
  batch_size: 128
  crispr_data: True
  SUBSET: False


OOD: 
  apply: False
  filter_dict:
    perturbation1: ''
    perturbation2: ''
    filter_single: 
      apply: False
      cond_name: 'condition'
      labels: ['']

  ctrl_name: ''
  stim_name: ''

growing_neurons:
  total_neurons: 16
  lr: 0.001
  decoder_name: 'decoder_post_train'

  prior_mappers:
    mappers:
      perturbation1_mapper:
        name: 'perturbation1'
        embedder_name: 'condition_embedder'

        collapse_target: True
        collapse_name: 'CBL'

      perturbation2_mapper:
        name: 'perturbation2'
        embedder_name: 'condition_embedder'

        collapse_target: True
        collapse_name: 'CNN1'

models:
  encoder_pretrain: 
    layers: [5446, 256, 16]
    hidden_activation: 'Sine'
    last_activation: 'Sine'
    xavier_init: True
    batch_norm: False

  decoder:
    layers: [16, 1024, 1024, 1024, 5446]
    hidden_activation: 'Sine'
    last_activation: False
    xavier_init: True
    batch_norm: False 

  encoder:
    layers: [16, 256, 1]
    hidden_activation: 'Sine'
    last_activation: 'Sine'
    xavier_init: True
    batch_norm: False
 
  mapper: 
    layers: [1, 256, 16]
    hidden_activation: 'Sine'
    last_activation: 'Sine'
    xavier_init: True
    batch_norm: False
  
decoder_parameters:
  use_scvi_decoder:
    apply: True
    n_layers: 3
    n_hidden: 1024

embedders:
  condition_embedder:
    n_classes: 232
    n_dim: 8
    
optimizers: 
  condition_optimizers:
    models: ['condition_embedder']
    lr: [0.001]

  decoder_optimizer:
    models: ['encoder_pretrain', 'decoder']
    lr: [0.0001, 0.0001, 0.0001]

losses:

  rec_from_latent_pretrain:
    fnc_name: 'nb_loss'
    apply: True
    pred_key: 'px_l'
    gt_key: 'x_inp'
    activate_at: 0
    stop_at: +.inf
    weight:  0.00001
    gradient_flow: 'all'

  recover_latent:
    fnc_name: 'recover_latent'
    apply: True
    latent_key: 'pre_latent'
    post_latent_key: 'map_latent_summed'
    activate_at: 0
    stop_at: +.inf
    weight: 0.002
    gradient_flow: 'all'

 
train:
  set_seed: 42
  
  main_train:
    epochs: 521

  evaluate: True

  criterions:

    r2_mean_criterion/10_all:
      criterion: 'max'    

evaluations:
  evaluate_reconstruction:
    interval: 40
    start_eval: 0
    stop_eval: +.inf
    dataloaders: ['train']
    kwargs:
      rec_key: 'reconstructed'
      gt_key: 'x_inp'

  get_mig:
    interval: 40
    start_eval: 0
    stop_eval: +.inf
    dataloaders: ['train']
    kwargs:
      latent_key: 'dis_latent_stack'
      label_keys: ['condition']

  context_transfer_crispr:
    interval: 40
    start_eval: 0
    stop_eval: +.inf
    dataloaders: ['all']
    kwargs:
      label_key: 'condition'
      rec_key: 'reconstructed_collapse'
      ctrl_name: 'ctrl'
    
      custom_name: ''
      n_degs_list_ood: [10, 20, 50, 100]
      n_degs_list_val: [10, 20, 50, 100]

load_from_checkpoint:
  apply: False
  experiment_path: ''
  epoch: 200000

save_experiment:
  apply: True
  experiment_path: 'weights/'
  save_weights:
    apply: True
    interval: 200
    
  save_best_weights:
    apply: True

save_gradients: 
  apply: True
  interval: 100