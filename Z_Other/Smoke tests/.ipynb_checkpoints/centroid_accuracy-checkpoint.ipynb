{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Centroid rank accuracy (Norman) — all genes\n",
    "\n",
    "This notebook computes the **centroid rank accuracy** metric across OOD perturbations for Norman, using **all genes**.\n",
    "\n",
    "### Metric definition\n",
    "For each perturbation \\(g\\) and method \\(m\\), let \\(\\mu_g\\) be the ground-truth mean expression vector (centroid) of stimulated cells for perturbation \\(g\\), and \\(\\hat\\mu_{g,m}\\) be the method’s predicted mean.\n",
    "\n",
    "Define Euclidean distances to all GT centroids:\n",
    "\n",
    "\\[\n",
    " d_{g\\to h}^{(m)} = \\lVert \\hat\\mu_{g,m} - \\mu_h \\rVert_2\n",
    "\\]\n",
    "\n",
    "Then the **centroid rank accuracy** for \\(g\\) is:\n",
    "\n",
    "\\[\n",
    " \\mathrm{CRA}_g^{(m)} = \\frac{1}{K-1}\\sum_{h\\neq g} \\mathbf{1}\\left[d_{g\\to h}^{(m)} > d_{g\\to g}^{(m)}\\right]\n",
    "\\]\n",
    "\n",
    "This is in \\([0,1]\\): 1.0 means the prediction for \\(g\\) is closest to \\(\\mu_g\\) among all \\(\\{\\mu_h\\}\\).\n",
    "\n",
    "### Notes\n",
    "- Uses **all genes** (fixed gene panel), so the metric is well-defined across perturbations.\n",
    "- By default, GT centroids are computed from **OOD split only** (matching your evaluation protocol).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def _to_dense(X):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        return X\n",
    "    return X.toarray()\n",
    "\n",
    "\n",
    "def centroid_rank_accuracy(true_means: pd.DataFrame, pred_means: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Compute CRA per perturbation.\n",
    "\n",
    "    true_means: index=pert, columns=genes\n",
    "    pred_means: index=pert, columns=genes (same order)\n",
    "\n",
    "    Returns: pd.Series index=pert with values in [0,1].\n",
    "    \"\"\"\n",
    "    if list(true_means.columns) != list(pred_means.columns):\n",
    "        raise ValueError(\"Gene order mismatch between true_means and pred_means\")\n",
    "    if list(true_means.index) != list(pred_means.index):\n",
    "        raise ValueError(\"Perturbation order mismatch between true_means and pred_means\")\n",
    "\n",
    "    D = cdist(pred_means.to_numpy(), true_means.to_numpy(), metric=\"euclidean\")  # (K,K)\n",
    "    self_d = np.diag(D)\n",
    "    K = D.shape[0]\n",
    "    if K < 2:\n",
    "        raise ValueError(\"Need at least 2 perturbations to compute CRA\")\n",
    "\n",
    "    # strict > : ties count as 0 (matches your original code)\n",
    "    score = (D > self_d[:, None]).sum(axis=1) / (K - 1)\n",
    "    return pd.Series(score, index=true_means.index, name=\"CRA\")\n",
    "\n",
    "\n",
    "def list_available_perts(pred_dir: Path, method: str) -> list[str]:\n",
    "    \"\"\"Return perts inferred from filenames in a method prediction folder.\"\"\"\n",
    "    files = sorted(pred_dir.glob(\"*.h5ad\"))\n",
    "    perts = []\n",
    "    for fp in files:\n",
    "        stem = fp.stem\n",
    "        if method.upper() == \"GEARS\":\n",
    "            perts.append(stem.replace(\"_\", \"+\"))\n",
    "        else:\n",
    "            perts.append(stem)\n",
    "    return perts\n",
    "\n",
    "\n",
    "def load_pred_mean_from_file(fp: Path, pert: str, method: str) -> np.ndarray:\n",
    "    \"\"\"Load a single prediction file and return the predicted mean vector for `pert`.\n",
    "\n",
    "    Handles GEARS mean stored in `.uns[...]` when available; otherwise uses mean of `.X`.\n",
    "    \"\"\"\n",
    "    ad = sc.read_h5ad(fp)\n",
    "\n",
    "    ad = ad[ad.obs['cond_harm_pred'] == pert]\n",
    "\n",
    "    # fallback: mean across all cells in ad.X\n",
    "    return _to_dense(ad.X).mean(axis=0).reshape(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scDisentangle', 'CPA', 'GEARS']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Choose scenario: 'combinatorially_seen' or 'single_only'\n",
    "scenario = 'combinatorially_seen'\n",
    "\n",
    "# Paths (relative to repo root)\n",
    "adata_path = Path('../../Datasets/preprocessed_datasets/norman.h5ad')\n",
    "\n",
    "pred_dirs = {\n",
    "    'scDisentangle': Path(f'../../Benchmarks/SCDISENTANGLE/Norman/predictions/{scenario}'),\n",
    "    'CPA': Path(f'../../Benchmarks/CPA/Norman/predictions/{scenario}'),\n",
    "    'GEARS': Path(f'../../Benchmarks/GEARS/Norman/predictions/{scenario}'),\n",
    "}\n",
    "\n",
    "# Which obs fields to use for GT\n",
    "cond_key = 'condition'   # contains 'A+B' perturbation names\n",
    "\n",
    "# NOTE: `Datasets/preprocessed_datasets/norman.h5ad` has no split column by default.\n",
    "# If you have a split column in a different AnnData, set split_key accordingly.\n",
    "split_key = None         # e.g., 'split'\n",
    "use_ood_only_for_gt = False\n",
    "\n",
    "# Output\n",
    "out_csv = Path(f'centroid_rank_accuracy__{scenario}__all_genes.csv')\n",
    "\n",
    "# Methods to include (keys must exist in pred_dirs)\n",
    "methods = list(pred_dirs.keys())\n",
    "methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common perts across methods: 128\n",
      "Example: ['AHR+FEV', 'AHR+KLF1', 'BCL2L11+BAK1', 'BCL2L11+TGFBR2', 'BPGM+SAMD1', 'BPGM+ZBTB1', 'CBL+CNN1', 'CBL+PTPN12', 'CBL+PTPN9', 'CBL+TGFBR2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SE/miniconda3/envs/trials/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n",
      "adata.X seems to be already log-transformed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 5446)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Discover perturbations available across all methods ---\n",
    "available = {}\n",
    "for m, d in pred_dirs.items():\n",
    "    if not d.is_dir():\n",
    "        raise FileNotFoundError(f\"Missing prediction directory for {m}: {d.resolve()}\")\n",
    "    available[m] = set(list_available_perts(d, m))\n",
    "\n",
    "common_perts = sorted(set.intersection(*[available[m] for m in methods]))\n",
    "print('Common perts across methods:', len(common_perts))\n",
    "print('Example:', common_perts[:10])\n",
    "\n",
    "# --- Load and normalize ground truth AnnData (match evaluation normalization) ---\n",
    "adata = sc.read_h5ad(adata_path)\n",
    "\n",
    "# normalize_total + log1p to match your compute_metrics_norman pipeline\n",
    "sc.pp.normalize_total(adata, target_sum=adata.uns['single_perts_median'])\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# --- Compute GT centroids for each pert (all genes) ---\n",
    "true_means = []\n",
    "for pert in common_perts:\n",
    "    mask = (adata.obs[cond_key] == pert)\n",
    "\n",
    "    # Optional: if you have a split column and want OOD-only GT.\n",
    "    if use_ood_only_for_gt:\n",
    "        if not split_key:\n",
    "            raise ValueError(\"use_ood_only_for_gt=True requires setting split_key to a valid adata.obs column\")\n",
    "        if split_key not in adata.obs:\n",
    "            raise KeyError(f\"split_key '{split_key}' not found in adata.obs\")\n",
    "        mask = mask & (adata.obs[split_key] == 'ood')\n",
    "\n",
    "    ad_true = adata[mask]\n",
    "    if ad_true.n_obs == 0:\n",
    "        raise ValueError(f\"No GT cells found for pert={pert} (use_ood_only_for_gt={use_ood_only_for_gt})\")\n",
    "\n",
    "    mu = _to_dense(ad_true.X).mean(axis=0).reshape(-1)\n",
    "    true_means.append(mu)\n",
    "\n",
    "true_means = pd.DataFrame(true_means, index=common_perts, columns=adata.var_names)\n",
    "true_means.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load predicted centroids for each method ---\n",
    "pred_means_by_method = {}\n",
    "\n",
    "for method in methods:\n",
    "    pred_dir = pred_dirs[method]\n",
    "    mus = []\n",
    "    for pert in common_perts:\n",
    "        fname = pert if method.upper() != 'GEARS' else pert.replace('+', '_')\n",
    "        fp = pred_dir / f\"{fname}.h5ad\"\n",
    "        if not fp.is_file():\n",
    "            raise FileNotFoundError(f\"Missing prediction file: {fp}\")\n",
    "\n",
    "        mu_hat = load_pred_mean_from_file(fp, pert=pert, method=method)\n",
    "        mus.append(mu_hat)\n",
    "\n",
    "    pred_means = pd.DataFrame(mus, index=common_perts, columns=true_means.columns)\n",
    "    pred_means_by_method[method] = pred_means\n",
    "\n",
    "# --- Compute CRA per pert and summarize ---\n",
    "scores = {}\n",
    "for method, pred_means in pred_means_by_method.items():\n",
    "    scores[method] = centroid_rank_accuracy(true_means, pred_means)\n",
    "\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df_percent = scores_df * 100.0\n",
    "\n",
    "display(scores_df.head())\n",
    "print('Mean CRA (percent):')\n",
    "print(scores_df_percent.mean(axis=0).sort_values(ascending=False))\n",
    "\n",
    "# Save\n",
    "scores_df_percent.to_csv(out_csv)\n",
    "print('Saved:', out_csv.resolve())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trials)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
